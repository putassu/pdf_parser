# Robust Excel Parser with LLM-Feedback Loop

## 1. Обзор системы
Данный парсер предназначен для интеллектуального извлечения данных из сложных XLSX-файлов с нестандартной топологией (смешанные анкеты, вложенные таблицы, реестры с пропусками). Система объединяет детерминированный алгоритм пространственной кластеризации с семантическим анализом через Large Language Models (LLM).

## 2. Архитектура и компоненты
Система состоит из трех ключевых модулей:
- **RobustExcelParser (Engine):** Ядро на базе `openpyxl`, выполняющее геометрический анализ ячеек и сегментацию.
- **ExcelProcessingDispatcher (Orchestrator):** Управляет циклом оптимизации, хранит историю попыток и выбирает лучший результат.
- **LLM Auditor (Feedback):** Анализирует превью блоков, выставляет оценку качества (`quality_score`) и дает рекомендации по смене гиперпараметров.

## 3. Алгоритм парсинга (Step-by-Step)

### Этап 1: Пространственная сегментация (Algorithmic)
Парсер не просто читает файл, он строит карту занятых областей:
1. **Cell Discovery:** Обход всех ячеек листа. Пустые ячейки игнорируются, но их координаты учитываются.
2. **Distance Clustering:** Группировка ячеек в блоки на основе допусков:
   - `V_TOLERANCE`: Максимальное количество пустых строк между данными внутри одного блока.
   - `H_TOLERANCE`: Максимальное количество пустых колонок.
3. **Region Typing:** Каждому региону присваивается тип на основе плотности и структуры:
   - `DATA_GRID`: Регулярная структура (таблица).
   - `DATA_FORM`: Пары ключ-значение или анкетные данные.

### Этап 2: Семантическая валидация (LLM Check)
Для каждого блока формируется «умное превью» (Head + Tail): первые и последние 5-6 строк. Это позволяет LLM увидеть начало (например, шапку анкеты) и конец (например, реестр услуг).
- **Детектор склейки:** Если начало блока — это `RECORD_FORM`, а конец — `DATA_GRID`, LLM помечает это как ошибку сегментации.
- **Детектор распада:** Если одна таблица разбита на 20 мелких фрагментов, LLM фиксирует низкий скор.

### Этап 3: Цикл оптимизации (Optimization Loop)
Система выполняет до `N` (по умолчанию 3) попыток парсинга:
1. **Попытка 1:** Пресет `Standard`. Сохранение в `initial_results.json`.
2. **LLM Score:** Оценка качества (0.0 - 1.0).
3. **Feedback:** Если скор < 0.9, LLM меняет пресет:
   - `Tight`: Уменьшение допусков (если данные склеились).
   - `Relaxed`: Увеличение допусков (если данные «рассыпались»).
4. **Final Selection:** После завершения цикла выбирается итерация с максимальным `quality_score` и сохраняется в `final_results.json`.

## 4. Ключевые гиперпараметры (Presets)

| Параметр | Tight | Standard | Relaxed |
| :--- | :--- | :--- | :--- |
| **V_TOLERANCE** | 1 | 2 | 6 |
| **H_TOLERANCE** | 1 | 3 | 5 |
| **MAX_CHARS_BLOCK** | 1500 | 3000 | 6000 |
| **MIN_TABLE_ROWS** | 3 | 5 | 10 |

## 5. Выходные данные
Финальный JSON содержит:
- `params_used`: Итоговые настройки, давшие лучший результат.
- `coverage`: Процент охвата значимых ячеек листа.
- `regions`: Массив извлеченных блоков с координатами, типами и данными.
- `ai_analysis`: Текстовое саммари структуры каждого листа от ИИ.
- `ai_score`: Финальный балл качества.

## 6. Требования к среде
- **Python 3.10+**
- **Ollama (модель gemma3:4b или аналоги)**
- **Библиотеки:** `openpyxl`, `aiohttp`, `pandas` (для расширенного анализа).

---
*Note for Data Scientists: Система спроектирована так, чтобы минимизировать ручную настройку под каждый тип документа. Основной фокус — на топологическом сходстве данных внутри одного блока.*
